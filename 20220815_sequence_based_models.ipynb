{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17dbed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6d2f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_fasta_file(path, PTM):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: string\n",
    "        path to .fasta file with sequences\n",
    "    PTM: list of strings\n",
    "        the phosphorylation site such as ['S', 'T']\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    id_phos_sites: numpy array\n",
    "        array of UniProtIDs and phosphorylation indices\n",
    "    phos_dict : dict\n",
    "        dictionary with Uniprot IDs as keys and phosphorylation sequences \n",
    "    \n",
    "    \"\"\"\n",
    "    fp = open(path, 'r+')\n",
    "    lines = []\n",
    "    with fp as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    ID = []\n",
    "    uniprot_ID = []\n",
    "    c = []\n",
    "    indx = []\n",
    "    p_ind = []\n",
    "    p = []\n",
    "\n",
    "    for i in range(0, len(lines), 2):\n",
    "        ID.append(lines[i])\n",
    "\n",
    "    for i in range(len(ID)):\n",
    "        uniprot_ID.append(ID[i].split(\"|\"))\n",
    "\n",
    "    for lis in range(len(uniprot_ID)):\n",
    "        for i in range(1, len(uniprot_ID[lis]), 2):\n",
    "            c.append(uniprot_ID[lis][i])\n",
    "    phosp = np.array(c)\n",
    "\n",
    "    ID = []\n",
    "    def split(word):\n",
    "        return list(word)\n",
    "\n",
    "    for i in range(1, len(lines), 2):\n",
    "        ID.append([lines[i]])\n",
    "\n",
    "    for lis in range(len(ID)):\n",
    "        for char in range(len(ID[lis])):\n",
    "            indx.append(split(ID[lis][char]))\n",
    "\n",
    "    for lis in range(len(indx)):\n",
    "        p = []\n",
    "        for i in range(len(indx[lis])):\n",
    "            for k in range(len(PTM)):\n",
    "                if indx[lis][i] == PTM[k]:\n",
    "                    p.append(i)\n",
    "        p_ind.append(tuple(p))\n",
    "    \n",
    "    p_ind = np.array(p_ind, dtype=tuple)\n",
    "    print(f\"p_ind: {p_ind}\")\n",
    "    print(f\"phosp: {phosp}\")\n",
    "    if len(p_ind) == 1:\n",
    "        id_phos_sites = np.zeros(shape=(1,2), dtype = object)\n",
    "        id_phos_sites[:,0] = phosp\n",
    "        id_phos_sites[:,1] = tuple(p_ind)\n",
    "    else:\n",
    "        id_phos_sites = np.vstack((phosp, p_ind)).T\n",
    "    phos_dict = dict(np.c_[phosp, ID])\n",
    "    print(f\"id_phos_sites: {id_phos_sites}\")\n",
    "    print(f\"phos_dict: {phos_dict}\")\n",
    "    return id_phos_sites, phos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a7afc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmers(k, phos_dict, PTM):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k : int\n",
    "        an odd number that specifies that length of the kmer with the\n",
    "        phosphorylation site in the middle\n",
    "    phos_dict : dict\n",
    "        dictionary with Uniprot IDs as keys and phosphorylation sequences \n",
    "    PTM: list of strings\n",
    "        the phosphorylation site such as ['S', 'T']\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kmer : 2D array\n",
    "        2D array with columns UniProt ID, phosphorylation index, k-mer\n",
    "\n",
    "    \"\"\"\n",
    "    kmer = []\n",
    "    ID = list(phos_dict.keys())\n",
    "    for q in tqdm(range(len(ID)), desc=\"Kmers\", position=0, leave=True):\n",
    "        for d in range(len(phos_dict[ID[q]])):\n",
    "            for t in range(len(PTM)):\n",
    "                if phos_dict[ID[q]][d] == PTM[t]:\n",
    "                    around_ind = int((k-1)/2)\n",
    "                    if d-around_ind < 0 and d+around_ind+1 < len(phos_dict[ID[q]]):\n",
    "                        c = d-0\n",
    "                        g = phos_dict[ID[q]][d-c:d+around_ind+1]\n",
    "                        kmer.append([ID[q], d, \"-\"*(around_ind-d) + g])\n",
    "                    elif d-around_ind >= 0 and d+around_ind+1 >= len(phos_dict[ID[q]]):\n",
    "                        c = len(phos_dict[ID[q]]) - d\n",
    "                        g = phos_dict[ID[q]][d-around_ind:d+c]\n",
    "                        kmer.append([ID[q], d, g + \"-\"*(d+around_ind+1-len(phos_dict[ID[q]]))])\n",
    "                    elif d-around_ind < 0 and d+around_ind+1 >= len(phos_dict[ID[q]]):\n",
    "                        c = d-0\n",
    "                        b = len(phos_dict[ID[q]]) - d\n",
    "                        g = phos_dict[ID[q]][d-c:d+b]\n",
    "                        kmer.append([ID[q], d, \"-\"*(around_ind-d) + g + \"-\"*(d+around_ind+1-len(phos_dict[ID[q]]))])\n",
    "                    else:\n",
    "                        kmer.append([ID[q], d, phos_dict[ID[q]][d-around_ind:d+around_ind+1]])\n",
    "    \n",
    "    kmer = np.array(kmer)\n",
    "    return kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47c9048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_predict(sequence_path, modification, cutoff):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence_path: string\n",
    "        path to .fasta file with sequences\n",
    "    modification: string\n",
    "        phos, glycosylation, hydroxyproline, CDK, CK2, MAPK, PKA, or PKC \n",
    "    cutoff: float\n",
    "        number between 0 and 1 to add PTM labels to k-mers\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    probability: numpy array\n",
    "        array with PTM indices and probability\n",
    "    \n",
    "    \"\"\"\n",
    "    if modification == \"glycosylation\":\n",
    "        PTM = ['N']\n",
    "    elif modification == \"hydroxyproline\":\n",
    "        PTM = ['P']\n",
    "    else:\n",
    "        PTM = ['S', 'T']\n",
    "    \n",
    "    id_phos_sites, phos_dict = processing_fasta_file(sequence_path, PTM)\n",
    "    kmer = kmers(35, phos_dict, PTM)\n",
    "    # One-hot encoding\n",
    "    alphabet = \"ARNDCEQGHILKMFPSTWYV-U\"\n",
    "\n",
    "    def convert_to_onehot(data):\n",
    "        #Creates a dict, that maps to every char of alphabet an unique int based on position\n",
    "        global char_to_int\n",
    "        char_to_int = dict((c,i) for i,c in enumerate(alphabet))\n",
    "        encoded_data = []\n",
    "        #Replaces every char in data with the mapped int\n",
    "        encoded_data.extend([char_to_int[char] for char in data])\n",
    "        return encoded_data\n",
    "\n",
    "\n",
    "    def tensor_encoding(k, x_data, depth):\n",
    "        indices = []\n",
    "        t2 = []\n",
    "        for i in range(len(x_data)):\n",
    "            indices.append(convert_to_onehot(x_data[i,2]))\n",
    "        for i in range(len(indices)):\n",
    "            t1 = tf.one_hot(indices[i], depth)\n",
    "            t2.append(t1)\n",
    "        return t2\n",
    "\n",
    "    tensor = tensor_encoding(35, kmer, 22)\n",
    "    np.save('dataset', tensor)\n",
    "    dataset = np.load('dataset.npy', allow_pickle=True).astype('float32')\n",
    "    dataset = tf.convert_to_tensor(dataset)\n",
    "    dataset = dataset.reshape(dataset.shape[0], 35, 22, 1)\n",
    "\n",
    "    # Recreate the exact same model, including its weights and the optimizer\n",
    "    new_model = tf.keras.models.load_model(f'{modification}_no_labels.h5')\n",
    "\n",
    "    # Show the model architecture\n",
    "    new_model.summary()\n",
    "\n",
    "    predictions = new_model.predict(dataset)\n",
    "    \n",
    "    if PTM == ['S', 'T']:\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i] > cutoff:\n",
    "                if phos_dict[kmer[i,0]][int(kmer[i,1])] == \"S\":\n",
    "                    phos_dict[kmer[i,0]] = phos_dict[kmer[i,0]][0:int(kmer[i,1])]+\"X\"+phos_dict[kmer[i,0]][int(kmer[i,1])+1:]        \n",
    "                elif phos_dict[kmer[i,0]][int(kmer[i,1])] == \"T\":\n",
    "                    phos_dict[kmer[i,0]] = phos_dict[kmer[i,0]][0:int(kmer[i,1])]+\"Z\"+phos_dict[kmer[i,0]][int(kmer[i,1])+1:]        \n",
    "        \n",
    "        kmer = kmers(35, phos_dict, ['S', 'T', 'X', 'Z'])\n",
    "\n",
    "        # One-hot encoding\n",
    "        alphabet = \"ARNDCEQGHILKMFPSTWYVXZ-U\"\n",
    "\n",
    "        tensor = tensor_encoding(35, kmer, 24)\n",
    "        np.save('dataset', tensor)\n",
    "        dataset = np.load('dataset.npy', allow_pickle=True).astype('float32')\n",
    "        dataset = tf.convert_to_tensor(dataset)\n",
    "        dataset = dataset.reshape(dataset.shape[0], 35, 24, 1)\n",
    "    else:\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i] > cutoff:\n",
    "                if phos_dict[kmer[i,0]][int(kmer[i,1])] == PTM[0]:\n",
    "                    phos_dict[kmer[i,0]] = phos_dict[kmer[i,0]][0:int(kmer[i,1])]+\"X\"+phos_dict[kmer[i,0]][int(kmer[i,1])+1:]        \n",
    "                \n",
    "        kmer = kmers(35, phos_dict, [PTM[0], 'X'])\n",
    "\n",
    "        # One-hot encoding\n",
    "        alphabet = \"ARNDCEQGHILKMFPSTWYVX-U\"\n",
    "\n",
    "        tensor = tensor_encoding(35, kmer, 23)\n",
    "        np.save('dataset', tensor)\n",
    "        dataset = np.load('dataset.npy', allow_pickle=True).astype('float32')\n",
    "        dataset = tf.convert_to_tensor(dataset)\n",
    "        dataset = dataset.reshape(dataset.shape[0], 35, 23, 1)       \n",
    "    \n",
    "\n",
    "    # Recreate the exact same model, including its weights and the optimizer\n",
    "    new_model = tf.keras.models.load_model(f'{modification}_with_labels.h5')\n",
    "\n",
    "    # Show the model architecture\n",
    "    new_model.summary()\n",
    "\n",
    "    predictions = new_model.predict(dataset)\n",
    "    probability = np.c_[kmer[:,1], predictions]\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29f528bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_ind: [(5, 25, 30, 42, 44, 45, 47, 48, 49, 50, 51) (6, 7, 20, 30, 34, 35) ()\n",
      " (8, 12, 13, 27, 30, 33, 40, 42, 52, 53, 55)]\n",
      "phosp: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10460\\1796972567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessing_fasta_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tests/resources/two_sequences.fasta'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"S\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10460\\2451331658.py\u001b[0m in \u001b[0;36mprocessing_fasta_file\u001b[1;34m(path, PTM)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mid_phos_sites\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mid_phos_sites\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphosp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[0mphos_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphosp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"id_phos_sites: {id_phos_sites}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\sitetack-Ufn6sMq3-py3.7\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 0 and the array at index 1 has size 4"
     ]
    }
   ],
   "source": [
    "print(processing_fasta_file('tests/resources/two_sequences.fasta', [\"S\",\"T\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c4328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
