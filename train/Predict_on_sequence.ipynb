{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651097a1-45af-473a-abd4-c04c3857245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfe97bee-bab4-4d2d-8859-3f2914498cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some helper functions\n",
    "def convert_to_onehot(data, alphabet):\n",
    "    #Creates a dict, that maps to every char of alphabet an unique int based on position\n",
    "    global char_to_int\n",
    "    char_to_int = dict((c,i) for i,c in enumerate(alphabet))\n",
    "    encoded_data = []\n",
    "    #Replaces every char in data with the mapped int\n",
    "    encoded_data.extend([char_to_int[char] for char in data])\n",
    "    return encoded_data\n",
    "\n",
    "def tensor_encoding(x_data, depth, type, alphabet, k=53):\n",
    "    indices = []\n",
    "    t2 = []\n",
    "    for i in range(len(x_data)):\n",
    "        indices.append(convert_to_onehot(x_data[i], alphabet))\n",
    "        if len(convert_to_onehot(x_data[i], alphabet)) != k:\n",
    "            print (x_data[i])\n",
    "            print (\"Length off\")\n",
    "    array=np.stack(indices, axis=0)\n",
    "    if type == 'emb':\n",
    "        return array\n",
    "    for i in tqdm(range(len(indices))):\n",
    "        t1 = tf.one_hot(indices[i], depth) # output: [9 x 23]\n",
    "        t2.append(t1)\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "695a8667-4c28-4002-ac30-477a2d1b4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change these for you particular model\n",
    "\n",
    "##############################################################################################################\n",
    "alphabet_with_labels = \"ARNDCEQGHILKMFPSTWYV@&-UX\"  #Use alphabets that were used in constructing the datasets\n",
    "alphabet_without_labels = \"ARNDCEQGHILKMFPSTWYV-UX\"  #These are the example alphabets\n",
    "PR=\"S\"\n",
    "PR2=\"T\"\n",
    "folder=f\"Example_data\"\n",
    "model=f\"PreSprint\"\n",
    "sequence=\"\"\n",
    "model_num=4  #Select model number to use, usually choose 1 as default or the upper median model in metric of choice\n",
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e6454aa-d23e-4de5-8b74-2f72b273f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmer(seq, location, k=53):\n",
    "    \"\"\"\n",
    "    Returns kmer of length k from a location and sequence. Ends are padded with \"-\"\n",
    "\n",
    "    \"\"\"\n",
    "    half=int((k-1)/2)\n",
    "    if location > len(seq): #Will not add to list of kmers\n",
    "        print (\"Site outside of seq bounds, site: \"+str(location)+\", sequnce length: \"+str(len(seq)))\n",
    "        kmer=''\n",
    "    elif location <= half: #To deal with sites near the n terminus\n",
    "        if location > len(seq)-half: #To deal with sequences shorter than k\n",
    "            gap=\"-\"*(half-location+1)\n",
    "            gap2=\"-\"*int(half-(len(seq)-location))\n",
    "            kmer=seq[0 : int(location+half)]\n",
    "            kmer=gap+kmer+gap2\n",
    "        else: \n",
    "            gap=\"-\"*(half-location+1)\n",
    "            kmer=seq[0 : int(location+half)]\n",
    "            kmer=gap+kmer\n",
    "    elif location > len(seq)-half: #To deal with sites near the C terminus\n",
    "        gap=\"-\"*int(half-(len(seq)-location))\n",
    "        kmer=seq[int(location-half-1): len(seq)]\n",
    "        kmer=kmer+gap\n",
    "    else:\n",
    "        kmer=seq[int(location-half-1): int(location+half)]\n",
    "    assert len(kmer) == 53\n",
    "    return kmer\n",
    "\n",
    "def predict (sequence, model_num, seq_name, folder=folder, model=model, PR=PR, PR2=PR2, k=53):\n",
    "    \"\"\"\n",
    "    Predicts the probability of a modification occuring at a given site\n",
    "    Runs the with and no labels model (to compare if there is a difference)\n",
    "\n",
    "    Sequence: Sequence containing only characters in the alphabet\n",
    "    model_num: Integer for which model to use from the 10-fold validation. Use 1 if unsure\n",
    "    seq_name: Name of the sequence to report\n",
    "    \"\"\"\n",
    "    trial_num=model_num\n",
    "    directory=f'{folder}/{model}/Trial{trial_num}'\n",
    "    labeled_model = tf.keras.models.load_model(f\"{directory}/emb_CNN_with_labels_{trial_num}.h5\")\n",
    "    unlabeled_model = tf.keras.models.load_model(f\"{directory}/emb_CNN_no_labels_{trial_num}.h5\")\n",
    "    \n",
    "    PR_sites=[i + 1 for i, char in enumerate(sequence) if char == PR]\n",
    "    PR_kmers= [get_kmer(sequence, s, k=k) for s in PR_sites]\n",
    "    if PR2=='':\n",
    "        PR2_sites=[]\n",
    "        PR2_kmers=[]\n",
    "    else:\n",
    "        PR2_sites=[i + 1 for i, char in enumerate(sequence) if char == PR2]\n",
    "        PR2_kmers= [get_kmer(sequence, s, k=k) for s in PR2_sites]\n",
    "\n",
    "    kmers=PR_kmers+PR2_kmers\n",
    "    sites=PR_sites+PR2_sites\n",
    "\n",
    "    tensor1 = tensor_encoding(kmers, 23, 'emb', alphabet_without_labels, k=k)\n",
    "    tensor2 = tensor_encoding(kmers, 23, 'emb', alphabet_with_labels, k=k)\n",
    "\n",
    "    nl_y_pred = unlabeled_model.predict(tensor1)[:,0]\n",
    "    l_y_pred = labeled_model.predict(tensor2)[:,0]\n",
    "\n",
    "    dict={\"Site\": sites, \"No labels model\":nl_y_pred, \"With PTM labels model\":l_y_pred}\n",
    "    df = pd.DataFrame(dict)\n",
    "\n",
    "    df.to_csv(f\"{folder}/{model}_{seq_name}_prediction_results.csv\")\n",
    "    print (df)\n",
    "    return (df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f47d7a98-5237-4973-b5f9-a408dda9e2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "    Site  No labels model  With PTM labels model\n",
      "0     10         0.661830               0.502870\n",
      "1     13         0.672783               0.469449\n",
      "2     36         0.430824               0.408572\n",
      "3     68         0.161512               0.077070\n",
      "4     92         0.452066               0.207154\n",
      "5    123         0.626476               0.641393\n",
      "6    134         0.631561               0.488063\n",
      "7      2         0.602398               0.584023\n",
      "8     42         0.483407               0.305094\n",
      "9     50         0.746502               0.762836\n",
      "10    52         0.621401               0.499851\n",
      "11    70         0.449655               0.540768\n",
      "12   128         0.773318               0.738562\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "    Site  No labels model  With PTM labels model\n",
      "0     10         0.545871               0.700567\n",
      "1     13         0.566638               0.671037\n",
      "2     36         0.281840               0.265242\n",
      "3     68         0.454883               0.455231\n",
      "4     92         0.470122               0.673074\n",
      "5    123         0.574206               0.800132\n",
      "6    134         0.425192               0.553525\n",
      "7      2         0.709808               0.735771\n",
      "8     42         0.669210               0.644399\n",
      "9     50         0.826953               0.843088\n",
      "10    52         0.432546               0.388469\n",
      "11    70         0.666195               0.681451\n",
      "12   128         0.711974               0.758612\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>No labels model</th>\n",
       "      <th>With PTM labels model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.545871</td>\n",
       "      <td>0.700567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.566638</td>\n",
       "      <td>0.671037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>0.281840</td>\n",
       "      <td>0.265242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>0.454883</td>\n",
       "      <td>0.455231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.673074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123</td>\n",
       "      <td>0.574206</td>\n",
       "      <td>0.800132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134</td>\n",
       "      <td>0.425192</td>\n",
       "      <td>0.553525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.709808</td>\n",
       "      <td>0.735771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42</td>\n",
       "      <td>0.669210</td>\n",
       "      <td>0.644399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>0.826953</td>\n",
       "      <td>0.843088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>52</td>\n",
       "      <td>0.432546</td>\n",
       "      <td>0.388469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70</td>\n",
       "      <td>0.666195</td>\n",
       "      <td>0.681451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>128</td>\n",
       "      <td>0.711974</td>\n",
       "      <td>0.758612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Site  No labels model  With PTM labels model\n",
       "0     10         0.545871               0.700567\n",
       "1     13         0.566638               0.671037\n",
       "2     36         0.281840               0.265242\n",
       "3     68         0.454883               0.455231\n",
       "4     92         0.470122               0.673074\n",
       "5    123         0.574206               0.800132\n",
       "6    134         0.425192               0.553525\n",
       "7      2         0.709808               0.735771\n",
       "8     42         0.669210               0.644399\n",
       "9     50         0.826953               0.843088\n",
       "10    52         0.432546               0.388469\n",
       "11    70         0.666195               0.681451\n",
       "12   128         0.711974               0.758612"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq_TNNC2=\"MTDQQAEARSYLSEEMIAEFKAAFDMFDADGGGDISVKELGTVMRMLGQTPTKEELDAIIEEVDEDGSGTIDFEEFLVMMVRQMKEDAKGKSEEELAECFRIFDRNADGYIDPEELAEIFRASGEHVTDEEIESLMKDGDKNNDGRIDFDEFLKMMEGVQ\"\n",
    "predict (test_seq_TNNC2, 2, \"TNNC2\")\n",
    "predict (test_seq_TNNC2, 9, \"TNNC2\", model=\"PostSprint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8e5e5-452f-4599-9582-275ca25e2ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
